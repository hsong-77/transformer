# transformer

paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

reference:
* [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
* [Transformers from Scratch in PyTorch](https://medium.com/the-dl/transformers-from-scratch-in-pytorch-8777e346ca51)
